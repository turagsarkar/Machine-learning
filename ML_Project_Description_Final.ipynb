{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXQGMJi8v-s"
      },
      "source": [
        "# **Part A (Analysis of the Given Dataset)**\n",
        "\n",
        "Dataset Description: Titanic Dataset\n",
        "\n",
        "![](https://cdn.pixabay.com/photo/2021/03/04/16/32/ship-6068668_1280.png)\n",
        "\n",
        "Data Dictionary:\n",
        "\n",
        "\n",
        "1.\t'Survival': 0 = No, 1 = Yes\n",
        "2.\t'Pclass': Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
        "3.\t'Sex': Sex\n",
        "4.\t'Age': Age in years\n",
        "5.\t'SibSp':  siblings/spouses aboard\n",
        "6.\t'Parch':  parents/children aboard\n",
        "7.\t'Ticket': Ticket number\n",
        "8.\t'Fare': Passenger fare\n",
        "9.\t'Cabin': Cabin number\n",
        "10.\t'Embarked': Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
        "\n",
        "\n",
        "The data has been split into two groups:\n",
        "1.\ttraining set (train.csv)\n",
        "2.\ttest set     (test.csv (without output (Survived)))\n",
        "3.  test set output (Survived) given in this csv file (gender_submission.csv)\n",
        "\n",
        "\\\\\n",
        "The training set should be used to build your machine-learning models.\n",
        "\n",
        "The test set should be used to see how well your model performs on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxnHImon8v_H"
      },
      "source": [
        "## 1. Provide an overview of the given Dataset including the Dataset Characteristics and Exploratory Data Analysis, data preprocessing and performance of different ML models. This section should be written after completing Part A."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Titanic dataset is one of the most popular datasets in Machine Learning. The Titanic dataset contains 1309 rows and 12 columns. Each row represents a passenger on the Titanic, and each column contains information about that passenger. This dataset contains information about passengers of the Titanic and whether they survived or not. It's a classification problem where the goal is to predict who survived and who didn't.\n",
        "\n",
        "\n",
        "Exploratory Data Analysis (EDA) is an important first step in any data analysis to understand the distribution, range and any anomalies in the data. We use pandas and seaborn libraries in Python to explore the data. In EDA, we analyze the data by plotting charts, graphs, and tables to reveal insights and patterns. With Titanic dataset, we perform EDA by checking for missing values, analyzing the distribution of categorical and numerical variables, understanding the survival rate by different groups of people, and visualizing the correlation between variables.\n",
        "\n",
        "\n",
        "Data preprocessing is the process of cleaning and transforming the raw data into a format that machine learning models can understand. We use different techniques to preprocess the Titanic dataset. Handling missing values, converting categorical variables into numerical variables, converting data type, and splitting the dataset into training and test sets are the preprocessing steps that we apply in this dataset.\n",
        "\n",
        "\n",
        "After preprocessing, we apply various classification algorithms to build ML models, such as logistic regression and decision trees . We also fine-tune the model parameters and use cross-validation for performance evaluation.\n"
      ],
      "metadata": {
        "id": "kbwCYWJqUbHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second dataset named Advertising which has 201 rows and 4 columns. The advertising dataset captures the sales revenue generated with respect to advertisement costs across multiple channels like radio, tv, and newspapers.\n",
        "\n",
        "For advertising dataset we apply various regression algorithms to build ML models, such as Linear regression and Decision tree regressor."
      ],
      "metadata": {
        "id": "rxwOxTDWOVdK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9LLLCzX8v_I"
      },
      "source": [
        "## 2.\tDataset Characteristics and Exploratory Data Analysis\n",
        "\n",
        "In this section, introduce your dataset. Mention number of rows, columns and other characteristics. Provide the histograms of data distribution and correlations among the variable (hints: heatmap, groupby, etc) with a suitable discussion. Try to stand out and be creative. (Add as many cells as you need). Note, we will be watching for copy-paste here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASoMD1nN8v_J"
      },
      "source": [
        "### 2.1 Load, view data and show analysis on data. Be creative. Investigate like a detective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1iykfM2BmYx",
        "outputId": "2bdc8a59-42c3-4258-ab95-a9def970a563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0x0stukDdWa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FRahHBM8v_J"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/CSE303 Project/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/CSE303 Project/test.csv\")\n",
        "gender_data = pd.read_csv(\"/content/drive/MyDrive/CSE303 Project/gender_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F-GP0gYBSMI"
      },
      "outputs": [],
      "source": [
        "display('Train Data:',train_data.head(), 'Test Data:',test_data.head(),'Gender Data:',gender_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV6DQNCbDMiX"
      },
      "outputs": [],
      "source": [
        "# Merging gender table and test table to dataframe 'gender_test'\n",
        "left = gender_data\n",
        "right = test_data\n",
        "\n",
        "gender_test = pd.merge(left, right, on=[\"PassengerId\"])\n",
        "gender_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4unCyilADPzN"
      },
      "outputs": [],
      "source": [
        "# Merging the created dataframe 'gender_test' to the existing dataframe 'train_data'\n",
        "df = pd.concat([train_data, gender_test])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aDxDbUsDXPu"
      },
      "outputs": [],
      "source": [
        "#Show all column names\n",
        "# Code Here\n",
        "c_name = df.columns.values\n",
        "print(c_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S748b1NDqu5"
      },
      "outputs": [],
      "source": [
        "# Overview about Columns, Range, Non-Null Value Counts, Memory Usage and Data Types (#df.dtpyes)\n",
        "# Code Here\n",
        "df.info()\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhEFX2LxD0Z5"
      },
      "outputs": [],
      "source": [
        "# Count rows and coulums\n",
        "# Code Here\n",
        "print(\"number of rows : \", df.shape[0])\n",
        "print(\"number of columns : \",df.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP3jCiibD9QM"
      },
      "outputs": [],
      "source": [
        "# Total cells in the dataset\n",
        "# Code Here\n",
        "print(\"number of cells : \",df.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFXZmTy-8v_K"
      },
      "source": [
        "### 2.2 Data Cleaning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sfXNQbM8v_L"
      },
      "source": [
        "#### Identifying duplicate values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5hqB8Hq8v_M"
      },
      "outputs": [],
      "source": [
        "# Code Here\n",
        "df.duplicated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWLiVue78v_M"
      },
      "source": [
        "#### Identifying missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QpvKLrK8v_N"
      },
      "outputs": [],
      "source": [
        "# Find the amount of missing values in each column\n",
        "# Code Here\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z4if2sCEdAY"
      },
      "outputs": [],
      "source": [
        "# Calculating the percentage of missing values:\n",
        "percantage_missing = df.isnull().sum() * 100 / len(df)\n",
        "print(percantage_missing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaiM9H-g8v_P"
      },
      "source": [
        "#### Visualisation of missing data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect missing values\n",
        "df.isnull()"
      ],
      "metadata": {
        "id": "TIZkZA5pm7vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUWrcUtG8v_R"
      },
      "outputs": [],
      "source": [
        "# Visualisation\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='inferno')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNZ0uEw08v_S"
      },
      "source": [
        "#### Dealing with missing values. Fix the missing value problem.\n",
        "\n",
        "\n",
        "\n",
        "1.   Do analysis using plots. Fix issues.\n",
        "\n",
        "2.   Provide an appropriate discussion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Wsa1gt8v_Y"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "df.Age.hist(bins=10,color='purple')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "print(\"The Median age of passengers is :\", int(df.Age.median()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.Age.fillna(28, inplace=True)"
      ],
      "metadata": {
        "id": "3wSPtl7vVhbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=\"Fare\",data=df)\n",
        "\n",
        "print(\"Mean value of Fare is :\",df.Fare.mean())\n",
        "print(\"Median value of Fare is :\",df.Fare.median())"
      ],
      "metadata": {
        "id": "Lay2yIAaV67g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Fare.fillna(df.Fare.median(), inplace=True)"
      ],
      "metadata": {
        "id": "Xc5Jby80XCoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Cabin',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "WKL6JOOUXMc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "kTuOvYiTXmpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Embarked',data=df)\n",
        "df['Embarked'].value_counts()"
      ],
      "metadata": {
        "id": "BuTcteMUXvmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Embarked.fillna('S',inplace=True)"
      ],
      "metadata": {
        "id": "rmQF16blYjl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "VpwSPHQ5Y4N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='inferno')"
      ],
      "metadata": {
        "id": "S42M0Tq6ZPr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_nUR5xy8H83"
      },
      "source": [
        " ##### Discuss your findings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given dataset we found some missing values in four columns. In the age column, there are 263 missing values. So we replaced the NaN values in the age column with the median age.There is a small fraction of fare values missing in the fare column which we filled using the median value since there a plenty of outliers in the data.There are 1014 missing values in Cabin column so we dropped it from the dataset. In the column named 'Embarked' there are two missing values. After analyzing the dataset, we found that most people embarked on their journey from Southhampton port. Hence, we filled the two missing values with \"S\".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Bc0C1qPVpzg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs4RVugB8v_Z"
      },
      "source": [
        "### 2.3 Analysing Patterns using Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1929wBZXHfIo"
      },
      "source": [
        "The data type of 'Sex' is an object, which will not be visible in a correlation. So, if we like to include the values of the column 'Sex' into the correlation matrix by creating a new column 'Sex_Number' and set the value 'female' to '1' and 'male' to '0'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvtpEV1AIGrg"
      },
      "outputs": [],
      "source": [
        "# Creating a new column 'SexNo' with the values '1' for 'female' and '0' for 'male'\n",
        "df['Sex_Number'] = np.where((df['Sex'] == \"female\"), 1, 0)\n",
        "# Checking if the column 'SexNo' has been added\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQEJVaB68v_Z"
      },
      "source": [
        "#### 2.3.1 Visualization of column correlation (use groupby). Also, plot Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_D3QdJm8v_a"
      },
      "outputs": [],
      "source": [
        "# Correlation table including the new column 'SexNo'\n",
        "correlation = df.corr()\n",
        "correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vozsp9X01XP"
      },
      "source": [
        "Correlation heatmaps are a type of plot that visualize the strength of relationships between numerical variables. Correlation plots are used to understand which variables are related to each other and the strength of this relationship.\n",
        "\n",
        "**seaborn.heatmap**\n",
        "\n",
        "Plot rectangular data as a color-encoded matrix.\n",
        "\n",
        "This is an Axes-level function and will draw the heatmap into the currently-active Axes if none is provided to the ax argument. Part of this Axes space will be taken and used to plot a colormap, unless cbar is False or a separate Axes is provided to cbar_ax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZYSLpFuIdHf"
      },
      "outputs": [],
      "source": [
        "# Visualisation of the corralation table\n",
        "\n",
        "plt.figure(figsize=(12,8), dpi=77)\n",
        "sns.heatmap(correlation, linecolor='white',linewidths=0.1, annot=True)\n",
        "plt.title('Correlation Matrix'.upper(), size=19, pad=13)\n",
        "plt.xlabel('Titanic Data')\n",
        "plt.ylabel('Titanic Data')\n",
        "plt.xticks(rotation=33)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8i6_GXtI3YR"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.1)? Write in your own words in this cell.\n",
        "\n",
        "Write below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create a correlation table and corelation matrix. We create it by calling upon the .corr() method on our dataframe.The correlation matrix provides us with an indication of how well (or not so well) each feature is correlated with each other. The returned value will be between -1 and +1, with higher correlations tending toward these endpoints, and poorer correlations tending towards 0.If we take a look at the colour bar on the right-hand side of the plot, we can see it starts at 1 at the top and goes down to around -0.013 at the bottom.We can control this range so that it is equal by using the vmin and vmax arguments and setting them to -1 and +1 respectively. However, if we add the numbers to the heatmap we can instantly see the values and still retain the variation in colour.To add numbers to our heatmap we simply add-in annot=True."
      ],
      "metadata": {
        "id": "QC-gPnWjXNdp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DugOt-Ou8v_b"
      },
      "source": [
        "#### 2.3.2 Visualization of column relationships (Categorical Variables)\n",
        "\n",
        "\n",
        "\n",
        "1.   Comparing two columns using different types of plots\n",
        "2.   Comparing multiple columns using different types of plots\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAzg4JteOJ3B"
      },
      "source": [
        "##### 2.3.2.1 Sex Proportion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtsA-ZoR8v_c"
      },
      "outputs": [],
      "source": [
        "male = (df['Sex'] == 'male').sum()\n",
        "female = (df['Sex']== 'female').sum()\n",
        "proportions = [male,female]\n",
        "\n",
        "plt.figure(figsize=(12,8), dpi=77)\n",
        "plt.pie(proportions, data=df, labels= ['Males', 'Females'], explode = (0.05,0), startangle=90, autopct='%1.1f%%', shadow=False)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Sex Proportion\", size=17, pad=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54LECG1fOZxj"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.1)? Write in your own words in this cell.\n",
        "\n",
        "Write below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, we can see the proportion of male and female in the titanic database through a pie chart. There were 64.4% male and 35.6% female on the ship.The proportion of male passengers is significantly more than female passangers."
      ],
      "metadata": {
        "id": "oA8NBZO6YwkE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFdxtSdSOlq4"
      },
      "source": [
        "##### 2.3.2.2 Age comparision of the people who survived and those who died"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS0ftO7QOw6k"
      },
      "outputs": [],
      "source": [
        "# How many people survived ('Survived' == 0)\n",
        "survived_data=df.Survived.value_counts().to_frame()\n",
        "survived_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y49Z8s09O1JZ"
      },
      "outputs": [],
      "source": [
        "pd.pivot_table(df, index=\"Survived\", values=['Pclass','SibSp', 'Parch', 'Fare'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDqH2CrMPBE7"
      },
      "outputs": [],
      "source": [
        "# Amount and average age of people who survived compared to those who died.\n",
        "df.groupby(['Survived']).Age.agg([len,min, max,'mean', 'median'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXbGo3jMP4sQ"
      },
      "outputs": [],
      "source": [
        "fem_p1_s0 =df.loc[(df.Sex == 'female') & (df.Pclass == 1) & (df.SibSp == 0)].Age.median()\n",
        "fem_p1_s1 =df.loc[(df.Sex == 'female') & (df.Pclass == 1) & (df.SibSp == 1)].Age.median()\n",
        "fem_p1_s2 =df.loc[(df.Sex == 'female') & (df.Pclass == 1) & (df.SibSp == 2)].Age.median()\n",
        "fem_p1_s3 =df.loc[(df.Sex == 'female') & (df.Pclass == 1) & (df.SibSp == 3)].Age.median()\n",
        "fem_p2_s0 =df.loc[(df.Sex == 'female') & (df.Pclass == 2) & (df.SibSp == 0)].Age.median()\n",
        "fem_p2_s1 =df.loc[(df.Sex == 'female') & (df.Pclass == 2) & (df.SibSp == 1)].Age.median()\n",
        "fem_p2_s2 =df.loc[(df.Sex == 'female') & (df.Pclass == 2) & (df.SibSp == 2)].Age.median()\n",
        "fem_p2_s3 =df.loc[(df.Sex == 'female') & (df.Pclass == 2) & (df.SibSp == 3)].Age.median()\n",
        "fem_p3_s0 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 0)].Age.median()\n",
        "fem_p3_s1 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 1)].Age.median()\n",
        "fem_p3_s2 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 2)].Age.median()\n",
        "fem_p3_s3 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 3)].Age.median()\n",
        "fem_p3_s4 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 4)].Age.median()\n",
        "fem_p3_s5 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 5)].Age.median()\n",
        "fem_p3_s8 =df.loc[(df.Sex == 'female') & (df.Pclass == 3) & (df.SibSp == 8)].Age.median()\n",
        "male_p1_s0 =df.loc[(df.Sex == 'male') & (df.Pclass == 1) & (df.SibSp == 0)].Age.median()\n",
        "male_p1_s1 =df.loc[(df.Sex == 'male') & (df.Pclass == 1) & (df.SibSp == 1)].Age.median()\n",
        "male_p1_s2 =df.loc[(df.Sex == 'male') & (df.Pclass == 1) & (df.SibSp == 2)].Age.median()\n",
        "male_p1_s3 =df.loc[(df.Sex == 'male') & (df.Pclass == 1) & (df.SibSp == 3)].Age.median()\n",
        "male_p2_s0 =df.loc[(df.Sex == 'male') & (df.Pclass == 2) & (df.SibSp == 0)].Age.median()\n",
        "male_p2_s1 =df.loc[(df.Sex == 'male') & (df.Pclass == 2) & (df.SibSp == 1)].Age.median()\n",
        "male_p2_s2 =df.loc[(df.Sex == 'male') & (df.Pclass == 2) & (df.SibSp == 2)].Age.median()\n",
        "male_p3_s0 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 0)].Age.median()\n",
        "male_p3_s1 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 1)].Age.median()\n",
        "male_p3_s2 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 2)].Age.median()\n",
        "male_p3_s3 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 3)].Age.median()\n",
        "male_p3_s4 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 4)].Age.median()\n",
        "male_p3_s5 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 5)].Age.median()\n",
        "male_p3_s6 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 6)].Age.median()\n",
        "male_p3_s8 =df.loc[(df.Sex == 'male') & (df.Pclass == 3) & (df.SibSp == 8)].Age.median()\n",
        "\n",
        "# Filling missing values with average age of women and men in each class\n",
        "def myfunc(age, pclass, sex, SibSp):\n",
        "    if pd.isnull(age) and pclass==1 and sex == 'female' and SibSp == 0:\n",
        "        age=fem_p1_s0\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'female' and SibSp == 1:\n",
        "        age=fem_p1_s1\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'female' and SibSp == 2:\n",
        "        age=fem_p1_s2\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'female' and SibSp == 3:\n",
        "        age=fem_p1_s3\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'female' and SibSp == 0:\n",
        "        age=fem_p2_s0\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'female' and SibSp == 1:\n",
        "        age=fem_p2_s1\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'female' and SibSp == 2:\n",
        "        age=fem_p2_s2\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'female' and SibSp == 3:\n",
        "        age=fem_p2_s3\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 0:\n",
        "        age=fem_p3_s0\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 1:\n",
        "        age=fem_p3_s1\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 2:\n",
        "        age=fem_p3_s2\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 3:\n",
        "        age=fem_p3_s3\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 4:\n",
        "        age=fem_p3_s4\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 5:\n",
        "        age=fem_p3_s5\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'female' and SibSp == 8:\n",
        "        age=df.Age.median()\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'male' and SibSp == 0:\n",
        "        age=male_p1_s0\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'male' and SibSp == 1:\n",
        "        age=male_p1_s1\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'male' and SibSp == 2:\n",
        "        age=male_p1_s2\n",
        "    elif pd.isnull(age) and pclass==1 and sex == 'male' and SibSp == 3:\n",
        "        age=male_p1_s3\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'male' and SibSp == 0:\n",
        "        age=male_p2_s0\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'male' and SibSp == 1:\n",
        "        age=male_p2_s1\n",
        "    elif pd.isnull(age) and pclass==2 and sex == 'male' and SibSp == 2:\n",
        "        age=male_p2_s2\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 0:\n",
        "        age=male_p3_s0\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 1:\n",
        "        age=male_p3_s1\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 2:\n",
        "        age=male_p3_s2\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 3:\n",
        "        age=male_p3_s3\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 4:\n",
        "        age=male_p3_s4\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 5:\n",
        "        age=male_p3_s5\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 6:\n",
        "        age=male_p3_s6\n",
        "    elif pd.isnull(age) and pclass==3 and sex == 'male' and SibSp == 8:\n",
        "        age=male_p3_s8\n",
        "    else:\n",
        "        age=age\n",
        "    return age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMe3hPT8P8ID"
      },
      "outputs": [],
      "source": [
        "# Creating a new columns 'Age_Filled_Na' with the new average age values\n",
        "df['Age_Filled'] = df.apply(lambda x: myfunc(x['Age'], x['Pclass'], x['Sex'], x['SibSp']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwDSRkJ1PGPg"
      },
      "outputs": [],
      "source": [
        "# Age comparision of the people who survived and those who died using a boxplot.\n",
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.boxplot(x=\"Survived\", y=\"Age_Filled\", data=df)\n",
        "plt.title(\"Comparison: Age of People who died / survived\", size=17, pad=13)\n",
        "plt.ylabel('Age')\n",
        "plt.xlabel(' ')\n",
        "plt.xticks([0, 1], ['Not Survived', 'Survived'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DSAvEnaQSPB"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.2)? Write in your own words in this cell.\n",
        "\n",
        "Write below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see that the number of women saved is more than nearly twice that of the number of males survived. They might have given more priority to female than male. The median age for both survived and non-survived passengers are equal. The mean value of survived people is 30.510986 and the mean value of the people who didn not survive is 28.931079. is From the boxplot of Age comparision of the people who survived and those who died, we find the lower quartile value is approximately 22 and higher quartile value is approximately 38.\n"
      ],
      "metadata": {
        "id": "IKjIyCmfZeq5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2tKtuPLTVwb"
      },
      "source": [
        "##### 2.3.2.3 The barplot compares the survival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDInKMJMTZ4R"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.barplot(x=\"Sex\", y=\"Survived\", data=df)\n",
        "plt.title(\"Survivors - Male & Female\", size=17, pad=13 )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqvV6w_KToYb"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.3)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above barplot we find that more females survived than males. I think one of the main reasons why more females survived than males in the Titanic dataset is due to the \"women and children first\" policy that was followed during the evacuation of the ship."
      ],
      "metadata": {
        "id": "V1B0Qg1zddq7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGfaIu0VTwIZ"
      },
      "source": [
        "##### 2.3.2.4 Comparison: Survivors - Male & Female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5DDm9obT15p"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.countplot(x=df['Sex'],hue=df['Survived'])\n",
        "plt.title(\"Comparison: Survivors - Male & Female\", size=17, pad= 13)\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys1GAJaLT5wU"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.4)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot we can see that the number of people who did not survive is nearly half that of those who survived.Though there were more male passengers than female passengers, but still female passengers survival ratio is higher than the male passengers survival ratio.So we can say that Females have very high chances of survival compared to the males."
      ],
      "metadata": {
        "id": "A9yA3owHfHIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNOAWJV1UdYT"
      },
      "outputs": [],
      "source": [
        "# Find percentage of men and women who survived\n",
        "df[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEDqS4hU0-K"
      },
      "source": [
        "##### 2.3.2.5 Compares the chance of survival for each ticket class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfcN5ldnVDSi"
      },
      "outputs": [],
      "source": [
        "df['Pclass'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI7x8zuOVGYc"
      },
      "outputs": [],
      "source": [
        "df.groupby(['Pclass', 'Survived']).Age.agg([len])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2CpXzVlVNoM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.barplot(x=\"Pclass\", y=\"Survived\", data=df)\n",
        "plt.title(\"Chance of Survival for each Ticket Class\", size=17, pad=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnQiSY7CVjML"
      },
      "outputs": [],
      "source": [
        "# Survived and not survived compared for each ticket class\n",
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.countplot(x=df['Pclass'],hue=df['Survived'])\n",
        "plt.title(\"Comparison: Survivors - Ticket Class\", size=17, pad=13)\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper left', prop={'size': 12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmUiUKf4VYa4"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.5)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above results, we can say that, 1st class has high chance of surviving than the other two classes.Although the majority of people (709) belonged to the Third class, the people who are in the first class got extra benefit while evacuating the ship."
      ],
      "metadata": {
        "id": "xKMJtrn_g1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0SVNh6OVoN7"
      },
      "source": [
        "##### 2.3.2.6 Chance of Survival for Passengers with Parents or Children"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOsoN_lvV17L"
      },
      "outputs": [],
      "source": [
        "# Amount and average age of women and man of each class who survived compared to those who died.\n",
        "df.groupby(['Sex','Survived', 'Pclass']).Age.agg([len,min, max,'mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lezOhPKL2120"
      },
      "outputs": [],
      "source": [
        "df['Parch'].value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WGB-XCv28oh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6), dpi=77)\n",
        "sns.barplot(x=\"Parch\", y=\"Survived\", data=df)\n",
        "plt.title(\"Chance of Survival for Passengers with Parents or Children\", size=17, pad=13)\n",
        "plt.xlabel('Number of Parents / Children')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOKIc7RY2-iz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8), dpi=77)\n",
        "sns.countplot(x=df['Parch'],hue=df['Survived'])\n",
        "plt.title(\"Survived - Parents or Children\", size=17, pad=12)\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 12})\n",
        "plt.xlabel('Parents / Children')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0O4wMVN3Ch5"
      },
      "outputs": [],
      "source": [
        "# Age of people with parents or children\n",
        "df.groupby(['Parch','Survived']).Age.agg([len, min, max])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljYjnGpE3Eu2"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.6)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the visualizations that those who traveled with a family appear to have a slight advantage.Those who traveled with 1 to 5 family members (parents or children) has the most chances of survival.On the other hand, those passengers who traveled alone has the fewer chances of survival."
      ],
      "metadata": {
        "id": "tjJ2JEYFg-PF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fj1BNy23PQB"
      },
      "source": [
        "##### 2.3.2.7 This barplot compares the chance of survival within a category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vll0xJIE3PCx"
      },
      "outputs": [],
      "source": [
        "df.SibSp.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSZvnSuw3OWZ"
      },
      "outputs": [],
      "source": [
        "df.groupby(['SibSp','Survived']).Age.agg([len, 'mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l12GjUD3eF9"
      },
      "outputs": [],
      "source": [
        "# This barplot compares the chance of survival within a category\n",
        "plt.figure(figsize=(12,6), dpi=77)\n",
        "sns.barplot(x=\"SibSp\", y=\"Survived\", data=df)\n",
        "plt.title(\"Chance of Survival for Passengers with Siblings or Spouses\", size=17, pad=13)\n",
        "plt.xlabel('Number of Siblings / Spouses')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvk4lnKH3t8i"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8), dpi=77)\n",
        "sns.countplot(x=df['SibSp'],hue=df['Survived'])\n",
        "plt.title(\"Survived - Siblings or Spouses\", size=17, pad=13)\n",
        "plt.xlabel('Siblings / Spouses')\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL9IbcLW3wLL"
      },
      "outputs": [],
      "source": [
        "df.groupby(['SibSp','Survived']).Age.agg([len, min, max, 'mean'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCEWeML03yV3"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.7)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above analysis we can see that, passengers having 0 or 1 siblings have good chances of survival.More number of siblings means Fewer chances of survival.So we can say that from the above analysis that those passengers who have more than 0 or 1 siblings have fewer chances of survival."
      ],
      "metadata": {
        "id": "wqDar_fnhj6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqOIqdQm33md"
      },
      "source": [
        "##### 2.3.2.8 Chance of Survival by Port of Embarkation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axi3FLTU33K5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.barplot(x=\"Embarked\", y=\"Survived\", data=df)\n",
        "plt.title('Chance of Survival by Port of Embarkation', size=17, pad=13)\n",
        "plt.xlabel('Port of Embarkation', size=13)\n",
        "plt.xticks([0, 1, 2],['Southampton', 'Cherbourd', 'Queenstown'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW6Xy9I94sga"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8), dpi=77)\n",
        "sns.countplot(x=df['Embarked'],hue=df['Survived'])\n",
        "plt.title(\"Comparison: Survivors by Port of Embarkation\", size=17, pad=13)\n",
        "plt.xlabel('Port of Embarkation')\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 12})\n",
        "plt.xticks([0, 1, 2],['Southampton', 'Cherbourd', 'Queenstown'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtC7QzZp4xw4"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.8)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot shows the survival rate based on port of embarkation. We saw earlier that the majority of passengers embarked from Southampton but Passengers leaving from Southampton also had the lowest chance of survival.Passengers who embarked from  port Cherbourg has the most chance of survival."
      ],
      "metadata": {
        "id": "y23he3LIiVMN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgDCuHYG45-T"
      },
      "source": [
        "##### 2.3.2.9 Average Age of Passengers with Siblings and  Parents or Children"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMGRSLDW5A3A"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6), dpi=77)\n",
        "sns.barplot(x=\"SibSp\", y=\"Age\", data=df)\n",
        "plt.title('Average Age of Passengers with Siblings', size=17, pad=13)\n",
        "plt.xlabel('Siblings')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHyiwEVs5cJk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8), dpi=77)\n",
        "sns.boxplot(x=\"Parch\", y=\"Age\", data=df)\n",
        "plt.title('Age of Passengers with Parents or Children', size=17, pad=13)\n",
        "plt.xlabel('Parents / Children')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGNDvVbv5iC8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6), dpi=77)\n",
        "sns.barplot(x=\"Parch\", y=\"Age\", data=df)\n",
        "plt.title('Average Age of Passengers with Parents or Children', size=17, pad=12)\n",
        "plt.xlabel('Parents / Children')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0HqyyWg5ltx"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.9)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we created a bar plot to see the average age of passengers with siblings. The x-axis represented siblings, and the y-axis represented age. People who had one sibling had the highest average age of the group.Second, we created a box plot to determine the age of passengers traveling with parents or children. The x-axis represented parents or children, and the y-axis represented age. This plot revealed that people with no siblings had the most outliers. The previous bar graph was about the average."
      ],
      "metadata": {
        "id": "zuA7m3yPi9LQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdwhnhgj5uJ2"
      },
      "source": [
        "##### 2.3.2.10 Age of Passengers for each Ticket Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKG6oK0550hf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6), dpi=77)\n",
        "sns.boxplot(x=\"Pclass\", y=\"Age\", data=df)\n",
        "plt.title('Age of Passengers for each Ticket Class', size=17, pad=13)\n",
        "plt.xlabel('Ticket Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV8m9Qq1557r"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.10)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a box plot to see the age of passengers for each ticket class. The x-axis represented ticket class, and the y-axis represented age. We can see from this graph that the more aged people are in the 1st class. We also see that, the people who went through third grade had the most outliers."
      ],
      "metadata": {
        "id": "larzaXsCjY3g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Kdto6Y6Apg"
      },
      "source": [
        "##### 2.3.2.11 Comparing multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dihgrL9M6Gmp"
      },
      "outputs": [],
      "source": [
        "# Comparison of Pclass, Age, Sex and Survivors\n",
        "g = sns.FacetGrid(df, col='Survived', row='Pclass', sharey=False, ylim=(0,300), hue='Sex', height=7)\n",
        "g.map_dataframe(sns.scatterplot, x='Age', y='Fare')\n",
        "g.set_axis_labels('Age', 'Fare')\n",
        "g.add_legend()\n",
        "# g.set_titles(col_template='', row_template='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfr9rDhS6JgJ"
      },
      "outputs": [],
      "source": [
        "# Comparison of Parch, Age, Sex and Survivors\n",
        "g = sns.FacetGrid(df, col='Survived', row='SibSp', sharey=False, ylim=(0,300), hue='Sex', height=7)\n",
        "g.map_dataframe(sns.scatterplot, x='Age', y='Fare')\n",
        "g.set_axis_labels('Age', 'Fare')\n",
        "g.add_legend()\n",
        "# g.set_titles(col_template='', row_template='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVJPp6_d6JnF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.histplot(df.Fare)\n",
        "plt.title('Fares Paid', size=17, pad=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTZJgdX16VJK"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(figsize=(22, 9))\n",
        "sns.countplot(x='Fare', hue='Survived', data=df)\n",
        "plt.xlabel('Fare', size=16, labelpad=10)\n",
        "plt.ylabel('Count', size=15, labelpad=10)\n",
        "plt.tick_params(axis='x', labelsize=13)\n",
        "plt.tick_params(axis='y', labelsize=15)\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
        "plt.title('Survial compared to Fare', size=20, y=1, pad=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMH9lLMZ6c4E"
      },
      "source": [
        " What do you undersend/find from the analysis above (section 2.3.2.11)? Write in your own words in this cell.\n",
        "\n",
        "Write below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a scatter plot using Seaborn to compare pclass, age, sex, and survivors. Furthermore, the plot displayed the survivors and non-survivors in terms of pclass. We found more variation in pclass=1 and survived=1 than in others.\n",
        "\n",
        "We created a scatter plot using Seaborn to compare parch, age, gender, and survivors. Furthermore, the plot displayed the survivors and non-survivors in terms of pclass. We found more variation in sibsp=1 and survived=1 than in others."
      ],
      "metadata": {
        "id": "0t1TwYjFkbnJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZvubuOP8v_c"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "Explain your data preprocessing steps including filling null values, dropping duplicates, encoding, dimensionality reduction etc. whichever is applicable. Appropriate data preprocessing can hugely impact your model’s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvZtRaOd7QyV"
      },
      "source": [
        "For encoding categorical variables you can use pandas (get_dummies).\n",
        "\n",
        "Convert categorical variable into dummy/indicator variables.\n",
        "\n",
        "Learn More:\n",
        "\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhD01a1X7xFx"
      },
      "source": [
        "**Examples**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut6dOua3BgiW"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmlsoJ_YBsKo"
      },
      "outputs": [],
      "source": [
        "train1 = train_data.copy()\n",
        "\n",
        "\n",
        "train1.drop(columns=['PassengerId','Name','Ticket','Cabin'],inplace=True)\n",
        "\n",
        "\n",
        "train1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNvMl6VGBze1"
      },
      "outputs": [],
      "source": [
        "data1 = train1.copy()\n",
        "\n",
        "data1 = pd.get_dummies(data1)\n",
        "\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQf95Y496nJ"
      },
      "source": [
        "**Now use the given dataset and perform the data preprocessing steps:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP0nnTpl8v_d"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()\n",
        "\n",
        "df1.drop(columns=['PassengerId','Name','Ticket'],inplace=True)\n",
        "\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "uMphUubJTE5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.copy()\n",
        "\n",
        "df2 = pd.get_dummies(df2)\n",
        "\n",
        "df2.head()"
      ],
      "metadata": {
        "id": "ve8YW1e4TUk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.Fare.astype(int)"
      ],
      "metadata": {
        "id": "e6HGBCk_zJvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.Age.astype(int)"
      ],
      "metadata": {
        "id": "YVjKGQsW3FJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "aROKg4UmTgMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPWWU6g88v_d"
      },
      "source": [
        "### **Write Here**\n",
        "\n",
        " What do you undersend/find from the analysis above (section 3)? Write in your own words in this cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing is an important step in any machine learning project, and it involves cleaning and transforming the dataset to prepare it for model training. Some data preprocessing steps for that we have used in this Titanic dataset include:\n",
        "\n",
        "\n",
        "1. Handling missing values: There are missing values in the \"Age\" ,\"Fare\",\"Embarked\" and \"Cabin\" columns, which we handled by imputing the missing values and dropping the columns entirely.\n",
        "\n",
        "2. Encoding categorical variables: The \"Sex\" and \"Embarked\" columns are categorical variables that need to be encoded into numerical values for machine learning algorithms to use. So we encoded them by using pandas(get_dummies.)\n",
        "\n",
        "3. Convert data type: We convert the data type of \"Age\" and \"Fare\" into int by using astype().\n",
        "\n"
      ],
      "metadata": {
        "id": "gkC0Awhbk6fE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3PHKT618v_e"
      },
      "source": [
        "## 4.\tMachine Learning Models\n",
        "\n",
        "\n",
        "\n",
        "1.   Develop machine learning models.\n",
        "2.   You may try changing different parameters to obtain better training\n",
        "accuracy.\n",
        "3. At least two models (with different parameters)\n",
        "\n",
        "\n",
        "\n",
        "Provide a brief description of the machine learning models you used. (Provide a detailed description of their parameter)\n",
        "\n",
        "Don’t copy-paste directly from the Internet! Write in your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAZbiMz2-X7a"
      },
      "source": [
        "### 4.1 Use Logistic regression to build your ML model for the Titanic dataset.\n",
        "\n",
        "At least two models (with different parameters). Hints: use the default parameters for one model and tuned-up (intuitively) parameter for improving accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJQvB5Gl8v_f"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.drop(\"Survived\",axis=1)\n",
        "y = df2[\"Survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)"
      ],
      "metadata": {
        "id": "FOPNZgzNl-Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(random_state=0, max_iter=1000)\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "acc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
        "acc_logreg"
      ],
      "metadata": {
        "id": "vf1CLbUFmhcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crossValidation\n",
        "cv_scores = cross_val_score(logreg,X,y,cv=5)\n",
        "\n",
        "np.mean(cv_scores)*100"
      ],
      "metadata": {
        "id": "RcaijOSynCqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=logreg.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5xlZnO8PnJSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train,y_train)\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "acc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n",
        "acc_decision_tree"
      ],
      "metadata": {
        "id": "ILpBevKjpVcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv1_scores = cross_val_score(decision_tree,X,y,cv=5)\n",
        "\n",
        "np.mean(cv1_scores)*100"
      ],
      "metadata": {
        "id": "cGZQWSqzxai5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Nuquaq8v_g"
      },
      "source": [
        "**Write Here**\n",
        "\n",
        "What do you undersend this above (section 4.1)? Write in your own words in this cell."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we applied Logistic regression to build your ML model for the Titanic dataset. By using the logistic regression model we get the accuracy ac = 87.28. Our score also depends on how we had split our training data using train_test_split. So we perform k-fold cross validation to get a more accurate score. The score after 5 folds is 85.26.Here we also used confusion matrix. Because confusion matrix presents a table layout of the different outcomes of the prediction and results of a classification problem and helps visualize its outcomes. We have also applied decision tree Classifier to build the ML model. By using this model with default parameters we got the accuracy score = 97.93."
      ],
      "metadata": {
        "id": "hLtuOUFEkunQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR1vtHEyEmnH"
      },
      "source": [
        "### 4.2 First analyse the 'Advertising dataset' as like you have observed in Titanic dataset. Then, use Linear Regression to build your ML model for the Advertising dataset.\n",
        "\n",
        "At least two models (with different parameters). Hints: use the default parameters for one model and tuned-up (intuitively) parameter for improving accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym2reU4KEmWU"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "dff = pd.read_csv(\"/content/drive/MyDrive/CSE303 Project/advertising.csv\")\n",
        "dff.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff.info()"
      ],
      "metadata": {
        "id": "6SZWgVhscAl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff.isnull().sum()"
      ],
      "metadata": {
        "id": "arw6el97cJtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dff.drop(['Sales'], axis=1)\n",
        "y = dff['Sales']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "lt-BFB-vcTmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "tygjHH2cdTNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(linreg.coef_)\n",
        "print(linreg.intercept_)"
      ],
      "metadata": {
        "id": "nVhPJSzrec35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = linreg.predict(X_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "iKGUmLdDfpwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "lr_r2 = metrics.r2_score(y_test, y_pred)\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"-------------------------------------\")\n",
        "print('MAE is %.2f'% mae)\n",
        "print('MSE is %.2f'% mse)\n",
        "print('R2 score is %.2f'% lr_r2)"
      ],
      "metadata": {
        "id": "nWmDTQj3owxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score = cross_val_score(linreg, X, y, cv=10)\n",
        "\n",
        "print(\"Cross-Val Results:\", cv_score)\n",
        "print(\"Cross-Val Mean:\", cv_score.mean())"
      ],
      "metadata": {
        "id": "Bm1u8r11BIxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "f = DecisionTreeRegressor()\n",
        "f.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "GMjuVPrCo1e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = f.predict(X_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "wp_GRBk2x_eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "dt_r2 = metrics.r2_score(y_test, y_pred)\n",
        "print(\"The model performance for testing set\")\n",
        "print(\"-------------------------------------\")\n",
        "print('MAE is %.2f'% mae)\n",
        "print('MSE is %.2f'% mse)\n",
        "print('R2 score is %.2f'% dt_r2)"
      ],
      "metadata": {
        "id": "c7lolE_ao7Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMjUfT4zFk6C"
      },
      "source": [
        "**Write Here**\n",
        "\n",
        "What do you undersend this above (section 4.2)? Write in your own words in this cell."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have used Linear Regression to build ML model for the Advertising dataset. Along with linear regression, decision tree regression were used in this part of the project. We got mean absolute error,mean squared error and r2 square using those different models. For Linear regression model, mean absolute error is 1.72, MSE value is 4.87 and R2 value is 0.84.For Decision tree regressor model, mean absolute error is 1.28, MSE value is 3.89 and R2 value is 0.87."
      ],
      "metadata": {
        "id": "ZYfa7nCvnyMY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbG1PNw78v_h"
      },
      "source": [
        "## 5.\tPerformance Evaluation and Discussion\n",
        "\n",
        "Use charts and figures appropriately to visualize and compare the performance of different models (for both the dataset, provide seperate comparison). Add as many cells as you need.\n",
        "\n",
        "\\\n",
        "\n",
        "Analyze the performance of the models and provide your hypothesis behind their performance, e.g. Why are some models performing better than others? Provide appropriate reasoning for your hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZzHdMaj8v_i"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "models = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression','Decision Tree'],\n",
        "    'Score': [ acc_logreg,  acc_decision_tree]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Linear Regression','Decision Tree'],\n",
        "    'Score': [ lr_r2,  dt_r2]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ],
      "metadata": {
        "id": "BWonnfO3z3eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aYegOxn8v_j"
      },
      "source": [
        "### **Write Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart, we can see that Decision Tree Classifier is giving the most accurate result(97.93%) than the other model for the titanic dataset.After Decision tree logistic regression gives the more accurate result. So we can say that the Decission Tree Classifier is the best model for the titanic dataset.\n",
        "\n",
        "For advertising dataset we can see that Decision Tree Classifier is giving the most accurate result(87.08%) than linear regression model.So we can say that the Decission Tree Regressor is the best model for the advertising dataset."
      ],
      "metadata": {
        "id": "hZOr6Dyypem5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqiP1ftFazMG"
      },
      "source": [
        "# **Part B (Analysis of the Dataset(s) assigned to your group)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxU8-WULcl3P"
      },
      "source": [
        "## 1. Provide an overview of the Dataset including the Dataset Characteristics and Exploratory Data Analysis, Data Preprocessing, and performance of different models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJU7_XXQeRCW"
      },
      "source": [
        "Electrical Grid Stability Simulated Data Set contains 10000 rows and 14 columns. Tthe 1st four columns represents the value of electricity producer.4th, 5th and 6th columns represents the consumption of nominal power. Then the next four columns represents the coefficient (gamma) proportional to price elasticity. The 13th column represents the maximal real part of the characteristic equation root and the lat column represents  the stability label of the system. This dataset contains information electrical grid stability and whether the system is stable or not. It's a classification problem where the goal is to predict the stability of the electrical grid.\n",
        "\n",
        "Exploratory Data Analysis (EDA) is an important first step in any data analysis to understand the distribution, range and any anomalies in the data. We use pandas and seaborn libraries in Python to explore the data. In EDA, we analyze the data by plotting charts, graphs, and tables to reveal insights and patterns. With This dataset, we perform EDA by checking for missing values, analyzing the distribution of categorical and numerical variables, understanding the stability of different grid system, and visualizing the correlation between variables.\n",
        "\n",
        "Data preprocessing is the process of cleaning and transforming the raw data into a format that machine learning models can understand. We use different techniques to preprocess the This Electrical Grid Stability dataset. As there is no missing value,we do not need to handle missing values. But some other preprocessing steps which we used in this dataset are - converting categorical variables into numerical variables, converting data type,normalizing the data,label encoding and splitting the dataset into training and test sets.\n",
        "\n",
        "After preprocessing, we apply various classification algorithms to build ML models, such as logistic regression,svc and decision trees. Then we fine-tune the model parameters and use cross-validation for performance evaluation.We also apply classifier algorithm to build ML models.\n",
        "As this is a classification problem the classification algorithm's performance is more better than regressor algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPwNIskNhEHI"
      },
      "source": [
        "## 2.\tDataset Characteristics and Exploratory Data Analysis\n",
        "\n",
        "In this section, introduce your dataset. Mention number of rows, columns and other characteristics. Provide the histograms of data distribution and correlations among the variable with a suitable discussion. Try to stand out and be creative. (Add as many cells as you need)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DGk4gEhiJp"
      },
      "source": [
        "### 2.1 Load, View Data and Show Analysis on Rows and Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-Ma89nNhldR"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "f6XRI8tZwHak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid = pd.read_csv(\"/content/drive/MyDrive/Data_for_UCI_named.csv\")\n",
        "\n",
        "smart_grid.head()"
      ],
      "metadata": {
        "id": "j5vVYuLvwKw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl_name = smart_grid.columns.values\n",
        "print(cl_name)"
      ],
      "metadata": {
        "id": "pB7E9DxQwudi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid.info()\n",
        "smart_grid.dtypes"
      ],
      "metadata": {
        "id": "XKQguVMExYrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of rows : \", smart_grid.shape[0])\n",
        "print(\"number of columns : \",smart_grid.shape[1])"
      ],
      "metadata": {
        "id": "OW5cLzH1xp49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSAAWG06ekQn"
      },
      "source": [
        "### 2.2 Data Cleaning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDdJgFihgVf8"
      },
      "source": [
        "#### Identifying duplicate values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCLMpzvegtHo"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "smart_grid.duplicated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R28LNrp5iWR7"
      },
      "source": [
        "#### Identifying missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irh4OrLRie9q"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "smart_grid.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf9z8Pwlid-3"
      },
      "source": [
        "#### Visualisation of missing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VK7yhJgifd8"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "smart_grid.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(smart_grid.isnull(),yticklabels=False,cbar=False,cmap='inferno')"
      ],
      "metadata": {
        "id": "VoylqDIeH3z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXWOYP6-ieI0"
      },
      "source": [
        "#### Dealing with missing values (How would you deal with missing values?) (Columns with missing data)\n",
        "\n",
        "\n",
        "\n",
        "1.   Do analysis using plots\n",
        "\n",
        "2.   Provide an appropriate discussion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "import missingno as msno\n",
        "smart_grid.info()"
      ],
      "metadata": {
        "id": "ZLFHLS0br_Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(smart_grid)"
      ],
      "metadata": {
        "id": "I9Wa3xnb2YDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(smart_grid)"
      ],
      "metadata": {
        "id": "_XsGwWSw2quf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there is no column with missing data, we have nothing to fix in this section."
      ],
      "metadata": {
        "id": "nx6tLAZvInec"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsSwQ-DOvm-6"
      },
      "source": [
        "### 2.3 Analysing Patterns using Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGkxFBOYv5Gt"
      },
      "source": [
        "#### Visualization of column correlation. Also, plot Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tekkwNW7vqyx"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "correlation = smart_grid.corr()\n",
        "correlation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10), dpi=77)\n",
        "sns.heatmap(correlation, linecolor='white',linewidths=0.1, annot=True)\n",
        "plt.title('Correlation Matrix'.upper(), size=19, pad=13)\n",
        "plt.xlabel('Electrical Grid Stability Simulated Data Set')\n",
        "plt.ylabel('Electrical Grid Stability Simulated Data Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8tL7JCzg3op8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDiDKokwPhS"
      },
      "source": [
        "#### Visualization of Linear Relationships of columns (Continuous Numerical Variables)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for axs_ind, feature_group in enumerate([\"tau\"]):\n",
        "    smart_grid.boxplot(column=[feature_group + str(i + 1) for i in range(4)], color=\"red\")\n",
        "\n",
        "plt.title(\"Reaction time\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GwhgA9G047oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for axs_ind, feature_group in enumerate([\"p\"]):\n",
        "    smart_grid.boxplot(column=[feature_group + str(i + 1) for i in range(4)], color=\"blue\")\n",
        "\n",
        "plt.title(\"Power production/consumption\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aYUdcDn76Nm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for axs_ind, feature_group in enumerate([\"g\"]):\n",
        "    smart_grid.boxplot(column=[feature_group + str(i + 1) for i in range(4)], color=\"purple\")\n",
        "\n",
        "plt.title(\"Willingness to adapt\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z3zwP5766T_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid.boxplot(column=\"stab\", color = \"green\")\n",
        "plt.title(\"Grid Stability\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PigSBleRmcGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eln4XP1wsw1"
      },
      "source": [
        "#### Visualization of column relationships (Categorical Variables)\n",
        "\n",
        "\n",
        "\n",
        "1.   Comparing two columns using different types of plots\n",
        "2.   Comparing multiple columns using different types of plots\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_612A-GwsUp"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "smart_grid[\"stabf\"].unique\n",
        "smart_grid[\"stabf\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid[\"stabf\"].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "rHNZjGCHrzzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ9tbZTRxHVU"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "Explain your data preprocessing steps including filling null values, dropping duplicates, encoding, dimensionality reduction etc. whichever is applicable. Appropriate data preprocessing can hugely impact your model’s performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization data\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "num_col=smart_grid.select_dtypes(include=[\"float64\"]).columns\n",
        "standard=StandardScaler()\n",
        "smart_grid[num_col]=standard.fit_transform(smart_grid[num_col])\n",
        "\n",
        "smart_grid.head()"
      ],
      "metadata": {
        "id": "6QgPPZQjLZWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labelEncoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "smart_grid[\"stabf\"]=label_encoder.fit_transform(smart_grid[\"stabf\"])\n",
        "\n",
        "smart_grid.head()"
      ],
      "metadata": {
        "id": "c-Bj9TayLman"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid1 = smart_grid.copy()\n",
        "\n",
        "smart_grid1.drop(columns=[\"p1\", \"p2\", \"p3\", \"p4\"],inplace=True)\n",
        "\n",
        "smart_grid1.head()"
      ],
      "metadata": {
        "id": "dVVVCE_uMLTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_grid1.info()"
      ],
      "metadata": {
        "id": "AO8I95g4QnSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk5rZm_-13-G"
      },
      "source": [
        "### **Write Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing is an important step in any machine learning project, and it involves cleaning and transforming the dataset to prepare it for model training. Some data preprocessing steps for that we have used in this Titanic dataset include:\n",
        "\n",
        "1. Normalization of the data: Normalization is a technique often applied as part of data preparation for machine learning. We use this technique to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information.\n",
        "\n",
        "2. Encoding categorical variables: The \"stabf\" column has categorical variables that need to be encoded into numerical values for machine learning algorithms to use. So we encoded them by using label encoder.\n",
        "\n",
        "3. Drop unnecessary column: We drop the colums named-p1, p2, p3, p4 because after analyzing the dataset we found out that there is no obvious relationship between power[x] columns and stability."
      ],
      "metadata": {
        "id": "N0_OeX4usRwl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_y73RFP274P"
      },
      "source": [
        "## 4.\tMachine Learning Models\n",
        "\n",
        "\n",
        "\n",
        "1.   Develop machine learning models.\n",
        "2.   You may try changing different parameters to obtain better training\n",
        "accuracy.\n",
        "3. At least two models (with different parameters)\n",
        "\n",
        "\n",
        "\n",
        "Provide a brief description of the machine learning models you used. (Provide a detailed description of their parameter)\n",
        "\n",
        "Don’t copy-paste directly from the Internet! Write in your own words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for best model finding we use lazypredict\n",
        "! pip install lazypredict\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_df = smart_grid.drop(['stabf',\"stab\"] ,axis='columns')\n",
        "y_df =  smart_grid[[ \"stabf\"]]\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=None)\n",
        "clf=LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models_train,predictions_train = clf.fit(X_train, X_train, y_train, y_train)\n",
        "models_test,predictions_test = clf.fit(X_train, X_test, y_train, y_test)\n",
        "models_train"
      ],
      "metadata": {
        "id": "0I3kQhiH-Bql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_test"
      ],
      "metadata": {
        "id": "Trc5322B_BK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test result visulaization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5, 10))\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "ax = sns.barplot(y=models_train.index, x=\"Accuracy\", data=models_test)"
      ],
      "metadata": {
        "id": "0Uz4uCoR_JNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BGLEKYL3A7h"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error,confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "eiSHDv06FtBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_df = smart_grid1.drop(['stabf',\"stab\"] ,axis='columns')\n",
        "y_df =  smart_grid1[\"stabf\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=None)\n",
        "\n",
        "#Logistic Regression\n",
        "clflg1=LogisticRegression()\n",
        "clflg1.fit(X_train,y_train)\n",
        "prediction_test = clflg1.predict(X_test)\n",
        "acc_clflg1 = sklearn.metrics.accuracy_score(y_test, prediction_test)*100\n",
        "acc_clflg1"
      ],
      "metadata": {
        "id": "ytwL7ouVKdbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(clflg1,x_df,y_df,cv=5)\n",
        "np.mean(cv_scores)*100"
      ],
      "metadata": {
        "id": "vZ1ITg0rxXuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test, prediction_test)"
      ],
      "metadata": {
        "id": "kfxIMsYabt1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm1 =confusion_matrix(y_test, prediction_test)\n",
        "print(cm1)\n",
        "\n",
        "clflg1.classes_\n",
        "disp = ConfusionMatrixDisplay(cm1,display_labels=['unstable','stable'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "fvjo_GnQHYBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction_test))"
      ],
      "metadata": {
        "id": "_lisKeOQDo3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_df = smart_grid1.drop(['stabf',\"stab\"] ,axis='columns')\n",
        "y_df =  smart_grid1[\"stabf\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=None)\n",
        "\n",
        "#Logistic Regrssion with parameter\n",
        "clflg2=LogisticRegression(max_iter = 1000 , random_state= 42)\n",
        "clflg2.fit(X_train,y_train)\n",
        "prediction_test = clflg2.predict(X_test)\n",
        "acc_clflg2 = sklearn.metrics.accuracy_score(y_test, prediction_test)*100\n",
        "acc_clflg2"
      ],
      "metadata": {
        "id": "lqt8mb30Io6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores1 = cross_val_score(clflg2,x_df,y_df,cv=10)\n",
        "np.mean(cv_scores1)*100"
      ],
      "metadata": {
        "id": "w7o0Zr09x2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm2 =confusion_matrix(y_test, prediction_test)\n",
        "print(cm2)"
      ],
      "metadata": {
        "id": "hKlrplBSLZ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clflg2.classes_\n",
        "disp= ConfusionMatrixDisplay(cm2,display_labels=['unstable','stable'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "AZPINFYIMUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction_test))"
      ],
      "metadata": {
        "id": "SZHaefBOA8cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error,confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "x_df = smart_grid1.drop(['stabf',\"stab\"] ,axis='columns')\n",
        "y_df =  smart_grid1[\"stabf\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=None)\n",
        "\n",
        "#Support Vector Classifier\n",
        "clfsvm1=svm.SVC()\n",
        "clfsvm1.fit(X_train,y_train)\n",
        "prediction_test = clfsvm1.predict(X_test)\n",
        "acc_clfsvm1 = sklearn.metrics.accuracy_score(y_test, prediction_test)*100\n",
        "acc_clfsvm1"
      ],
      "metadata": {
        "id": "HYuaujoc2N3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test, prediction_test)"
      ],
      "metadata": {
        "id": "DERgHNfPbL36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm3 =confusion_matrix(y_test, prediction_test)\n",
        "print(cm3)\n",
        "clfsvm1.classes_\n",
        "disp= ConfusionMatrixDisplay(cm3,display_labels=['unstable','stable'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "5lZt9RNS2bfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction_test))"
      ],
      "metadata": {
        "id": "BRbgoLptBirV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error,confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "x_df = smart_grid1.drop(['stabf',\"stab\"] ,axis='columns')\n",
        "y_df =  smart_grid1[\"stabf\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=None)\n",
        "\n",
        "#Support Vector Classifier with parameter\n",
        "clfsvm2=svm.SVC(kernel='sigmoid',C=1000.0,gamma=1e-05)\n",
        "clfsvm2.fit(X_train,y_train)\n",
        "prediction_test = clfsvm2.predict(X_test)\n",
        "acc_clfsvm2 = sklearn.metrics.accuracy_score(y_test, prediction_test)*100\n",
        "acc_clfsvm2"
      ],
      "metadata": {
        "id": "Eodlw9wpNePb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm4 =confusion_matrix(y_test, prediction_test)\n",
        "print(cm4)\n",
        "clfsvm2.classes_\n",
        "disp = ConfusionMatrixDisplay(cm4,display_labels=['unstable','stable'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "NqIVOUgZOpmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, prediction_test))"
      ],
      "metadata": {
        "id": "k8dGQoMxBoZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tgkPDHR59TJ"
      },
      "source": [
        "### **Write Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We applied Logistic regression to build your ML model for this dataset. By using the default parameters for logistic regression model we get the accuracy ac = 80.7. Our score also depends on how we had split our training data using train_test_split. So we perform k-fold cross validation to get a more accurate score. The score after 5 folds is 81.52.After that we again use logistic regression with different parameters.This time we got slightly better accuracy than the privious model which is 81.15.we perform k-fold cross validation to get a more accurate score. The score after 10 folds is 81.54. Here we also used confusion matrix. Because confusion matrix presents a table layout of the different outcomes of the prediction and results of a classification problem and helps visualize its outcomes. We have also applied support vector Classifier to build the ML model. By using this model with default parameters we got the accuracy score = 96.55.We have also applied SVC with different parameter and got the accuracy score which is 80.80."
      ],
      "metadata": {
        "id": "qCkQhVfuLudo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDT9-gO6UfJ"
      },
      "source": [
        "## 5.\tPerformance Evaluation and Discussion\n",
        "\n",
        "Use charts and figures appropriately to visualize and compare the performance of different models. (Add as many cells as you need)\n",
        "\n",
        "\\\n",
        "\n",
        "Analyze the performance of the models and provide your hypothesis behind their performance, e.g. Why are some models performing better than others? Provide appropriate reasoning for your hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_KFkQlP66vK"
      },
      "outputs": [],
      "source": [
        "# Code Here (Add as many cells as you need)\n",
        "models = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression(Default)','Logistic Regression', 'Support Vector Classifier(Default)', 'Support Vector Classifier'],\n",
        "    'Score': [acc_clflg1, acc_clflg2, acc_clfsvm1, acc_clfsvm2 ]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRLhtjzD66ZG"
      },
      "source": [
        "### **Write Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart, we can see that Support Vector Classifier with default parameter is giving the most accurate result(96.55%) than the other models for the Electrical grid stability simulated dataset. After Support Vector Classifier logistic regression with different parameters gives the more accurate result. We also perform k-fold cross validation to get a more accurate score. But the accuracy rate is still lower than the support vector classifier. So we can say that the Support Vector Classifier is the best model for this dataset. One of the reason behind this can be that the parameters of the supoort vector classifier works best for our dataset.Another reason is that in out dataset the predictors do certainly determine thre responses, in the cases like this SVC do better. Though there is a chance of overfitting the data in this case, as the accuracy rate for the Support vector classifier with default parameter is nearly 100. So we change the parameter of the support vector Classifier model and get the accuracy rate nearly 80."
      ],
      "metadata": {
        "id": "4UThzGADObGl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LDdJgFihgVf8",
        "R28LNrp5iWR7",
        "xf9z8Pwlid-3",
        "hXWOYP6-ieI0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('env_tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "5df4995f4205929e0e7a5839a3f9bdb0ead66b703c002bad5d5fcff442b16b20"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}